<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta name="description" content="" />
  <meta name="author" content="" />
  <title>Tahsin Zaman Jilan</title>
  <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />

  <!-- Font Awesome icons (free version)-->
  <script src="https://use.fontawesome.com/releases/v5.15.3/js/all.js" crossorigin="anonymous"></script>

  <!-- Google fonts-->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />

  <!-- Core theme CSS (includes Bootstrap)-->
  <!-- CSS only -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
  <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
  <!-- Navigation-->
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Tahsin Zaman Jilan</span>
      <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
          src="assets/img/jilan1.jpg" alt="..." /></span>
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
      aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
        </li>
      </ul>
    </div>
  </nav>
  
  <!-- Page Content-->
  <div class="container-fluid p-0">
    <!-- About-->
    <section class="resume-section" id="about">
      <div class="resume-section-content">
        <h1 class="mb-0">
          Tahsin Zaman
          <span class="text-secondary">Jilan</span>
        </h1>
        <td>
          
          <p class="content">Software Engineer, Pathao Limited<br>
           Dhaka, Bangladesh<br>
           <strong>Email</strong>: <a href="mailto:tahsin.zaman.jilan@g.bracu.ac.bd">tahsin.zaman.jilan@g.bracu.ac.bd</a> 
            <!-- <strong class=“red”> This website last updated on January 2023</strong> -->
          </p>
       </td>
        <!-- <div class="subheading mb-3">
          Dhaka, Bangladesh · (880) 151-5644497 ·
          <a href="mailto:ibna.kowsar@g.bracu.ac.bd">ibna.kowsar@g.bracu.ac.bd</a>
        </div> -->
        <p class="lead mb-4" style="text-align: justify;">
          <!-- <p>Welcome to my portfolio website! </p> -->
        <p>I'm currently Software Engineer at Pathao.
        </p>
<p>I am a researcher exploring the security and robustness of Large Language Models (LLMs), with a focus on mitigating vulnerabilities such as prompt injection and goal hijacking. My work involves designing novel defense mechanisms, leveraging techniques like defensive prompting and Chain of Thought reasoning to enhance AI reliability. Beyond AI security, I have worked on deep learning applications in computer vision and NLP, including explainable AI for medical imaging and hate speech detection.

  In addition to research, I have experience as a frontend engineer, developing scalable web applications and optimizing user interfaces with modern frameworks. My background in software engineering complements my research by allowing me to implement, test, and deploy AI-driven solutions effectively.
</p> </p>
      
<!--         <p style="color:red;"><b>I am looking for Phd opportunities.</b></p> -->
        <p class="lead mb-1">
          My research interests include:
          
          <li><b>Large Language Models</b></li>
          <li><b>AI Security</b></li>
          <li><b>Machine Learning & Deep Learning</b></li>
          <li><b>Computer Vision</b></li>
          <li><b>NLP</b></li>
        </p>
        <div class="mb-5">
          <a target="_blank" href="./assets/papers/CV_Tahsin.pdf">
            <button class="btn btn-success">
              <i class="fa fa-file-pdf me-2" style="color:#FFF"></i>My Resume
            </button>
          </a>
        </div>
        <div class="social-icons">
          <a class="social-icon linkedin" href="https://www.linkedin.com/in/tahsin-zaman-jilan-b16102204/"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path fill="#FFF" d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg></a>
          <a class="social-icon github" href="https://github.com/Tahsin-Zaman-Jilan"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path fill="#FFF" d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
          <a class="social-icon scholar" href="https://scholar.google.com/citations?user=5W82C9sAAAAJ&hl=en&authuser=1"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Google Scholar</title><path fill="#FFF" d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"/></svg></a>
          <a class="social-icon researchgate" href="https://www.researchgate.net/profile/Tahsin_Jilan?ev=hdr_xprf"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>ResearchGate</title><path fill="#FFF" d="M19.586 0c-.818 0-1.508.19-2.073.565-.563.377-.97.936-1.213 1.68a3.193 3.193 0 0 0-.112.437 8.365 8.365 0 0 0-.078.53 9 9 0 0 0-.05.727c-.01.282-.013.621-.013 1.016a31.121 31.123 0 0 0 .014 1.017 9 9 0 0 0 .05.727 7.946 7.946 0 0 0 .077.53h-.005a3.334 3.334 0 0 0 .113.438c.245.743.65 1.303 1.214 1.68.565.376 1.256.564 2.075.564.8 0 1.536-.213 2.105-.603.57-.39.94-.916 1.175-1.65.076-.235.135-.558.177-.93a10.9 10.9 0 0 0 .043-1.207v-.82c0-.095-.047-.142-.14-.142h-3.064c-.094 0-.14.047-.14.141v.956c0 .094.046.14.14.14h1.666c.056 0 .084.03.084.086 0 .36 0 .62-.036.865-.038.244-.1.447-.147.606-.108.385-.348.664-.638.876-.29.212-.738.35-1.227.35-.545 0-.901-.15-1.21-.353-.306-.203-.517-.454-.67-.915a3.136 3.136 0 0 1-.147-.762 17.366 17.367 0 0 1-.034-.656c-.01-.26-.014-.572-.014-.939a26.401 26.403 0 0 1 .014-.938 15.821 15.822 0 0 1 .035-.656 3.19 3.19 0 0 1 .148-.76 1.89 1.89 0 0 1 .742-1.01c.344-.244.593-.352 1.137-.352.508 0 .815.096 1.144.303.33.207.528.492.764.925.047.094.111.118.198.07l1.044-.43c.075-.048.09-.115.042-.199a3.549 3.549 0 0 0-.466-.742 3 3 0 0 0-.679-.607 3.313 3.313 0 0 0-.903-.41A4.068 4.068 0 0 0 19.586 0zM8.217 5.836c-1.69 0-3.036.086-4.297.086-1.146 0-2.291 0-3.007-.029v.831l1.088.2c.744.144 1.174.488 1.174 2.264v11.288c0 1.777-.43 2.12-1.174 2.263l-1.088.2v.832c.773-.029 2.12-.086 3.465-.086 1.29 0 2.951.057 3.667.086v-.831l-1.49-.2c-.773-.115-1.174-.487-1.174-2.264v-4.784c.688.057 1.29.057 2.206.057 1.748 3.123 3.41 5.472 4.355 6.56.86 1.032 2.177 1.691 3.839 1.691.487 0 1.003-.086 1.318-.23v-.744c-1.031 0-2.063-.716-2.808-1.518-1.26-1.376-2.95-3.582-4.355-6.074 2.32-.545 4.04-2.722 4.04-4.9 0-3.208-2.492-4.698-5.758-4.698zm-.515 1.29c2.406 0 3.839 1.26 3.839 3.552 0 2.263-1.547 3.782-4.097 3.782-.974 0-1.404-.03-2.063-.086v-7.19c.66-.059 1.547-.059 2.32-.059z"/></svg></a>
        </div>
      </div>
    </section>
    <hr class="m-0" />

    <!-- Experience-->
    <section class="resume-section" id="experience">
      <div class="resume-section-content">
        <h2 class="mb-5">Experience</h2>
        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">Associate Software Engineer</h4>
            <div class="subheading mb-3">Pathao</div>
            <p>
              <li>Developed a points management dashboard using NUXT, REST API, and PINIA, improving data flow efficiency by 20%</li>
              <li>Enhanced mobile app responsiveness with Remix, boosting mobile user engagement by 40% and ensuring accessibility</li>
              <li>Designed intuitive, PRIMEVUE-based UI components, significantly improving user satisfaction and overall engagement</li>
            </p>
          </div>
          <div class="flex-shrink-0"><span class="text-primary">May 2024 - January 2025</span></div>
        </div>
        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">Software Engineer Intern</h4>
            <div class="subheading mb-3">Pathao</div>
            <p>
              <li>Built an interactive route visualization map using Leaflet, improving navigation and user experience</li>
              <li>Used Vue and Vuex for state management, ensuring seamless data handling and performance</li>
            </p>
          </div>
          <div class="flex-shrink-0"><span class="text-primary">January 2024 - April 2025</span></div>
            </div>
      </div>
    </section>
    <hr class="m-0" />

    <!-- Education-->
    <section class="resume-section" id="education">
      <div class="resume-section-content">
        <h2 class="mb-5">Education</h2>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h3 class="mb-0">BRAC University</h3>
            <div class="subheading mb-3">Bachelor of Science</div>
            <div>Computer Science & Engineering</div>
            <p>CGPA: 3.37/4.00</p>
            <p style="color:black"><b>Thesis Title:</b> An Interpretable Diagnosis of Retinal Diseases Using Vision Transformer and Grad-CAM</p>
              <h5 class="mb-1">Abstract</h5>
            <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;font-size: 15px;">Early detection of retinal diseases is very crucial to prevent partial or complete blindness. This research presents a novel, interpretable diagnosis framework that combines VGG- 16 and Swin Transformer models and then visualized through Grad-CAM to address the challenge of multi-label classification in retinal disease detection. Using the OCT images, we have developed a unique hybrid model that integrates the power of both Convolutional Neural Networks and Vision Transformers. This model does not only classifies images but also gives a clear visual explanations of the network's decisions through gradient-weighted class activation mapping which is also known as GRAD-CAM. The VGG-16 achieved an accuracy of 88.88% whereas the Vision Transformer reached 91.39%. On the other side, Our fine-tuned hybrid model significantly outperformed individual components. Achieving an accuracy of 98.8%, this model demonstrated its potential as a powerful tool for retinal disease detection.</p>
            </div>
          <div class="flex-shrink-0">
            <span class="text-primary">2020 - 2024</span>
          </div>
        </div>

        <!-- <div class="d-flex flex-column flex-md-row justify-content-between">
          <div class="flex-grow-1">
            <h3 class="mb-0">Milestone College</h3>
            <div class="subheading mb-3">Higher School Certificate</div>
            <div>Science</div>
            <p>GPA: 5.00/5.00</p>
          </div>
          <div class="flex-shrink-0">
            <span class="text-primary">2014 - 2016</span>
          </div>
        </div> -->
      </div>
    </section>
    <hr class="m-0" />

    <!-- Publications-->
    <section class="resume-section" id="publications">
      <div class="resume-section-content">
        <h2 class="mb-5">Publications</h2>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <!-- ADD NEW PAPER -->
          
          <div class="flex-grow-1">
            <h4 class="mb-0">
              Attention-based Imputation of Missing Values in Electronic Health Records Tabular Data
            </h4>
            <div class="subheading mb-3">
              <p><strong>Tahsin Zaman Jilan</strong>, Shourav B. Rabbani, Manar D. Samad</p>
              <p>
                International Conference on Pattern Recognition (ICHI 2024)
              </p>
              <!-- <p>
                  2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
                  Bangladesh
                </p> -->
              
          <a target="_blank" href="" title="Attention-based Imputation of Missing Values in Electronic Health Records Tabular Data"><i
            class="fa fa-file-pdf me-2"></i>Paper
          </a>
          </div>
            <div class="textarea">
              <h5 class="mb-1">Abstract</h5>
              <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;font-size: 15px;">
                The imputation of missing values (IMV) in electronic health records tabular data is crucial to enable machine learning for patient-specific predictive modeling. 
                While IMV methods are developed in biostatistics and recently in machine learning, deep learning-based solutions have shown limited success in learning tabular data. 
                This paper proposes a novel attention-based missing value imputation framework that learns to reconstruct data with missing values leveraging between-feature (self-attention) or between-sample attentions. 
                We adopt data manipulation methods used in contrastive learning to improve the generalization of the trained imputation model. The proposed self-attention imputation method outperforms state-of-the-art statistical and machine learning-based (decision-tree) imputation methods, reducing the normalized root mean squared error by 18.4% to 74.7% on five tabular data sets and 52.6% to 82.6% on two electronic health records data sets. 
                The proposed attention-based missing value imputation method shows superior performance across a wide range of missingness (10% to 50%) when the values are missing completely at random.
              </p>
            </div>
            <!-- <p>• Segmentation & Recognition of Bangla, Assamese and English (Handwritten, Typewritten, Computer Composed
              & Printed) characters</p> -->
            <p>
              • Accepted in ICHI2024 [will be online soon]
            </p>
          
          </div>
          </div>

          <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">
              A Deep Learning Based Unified Solution for Character Recognition
            </h4>
            <div class="subheading mb-3">
              <p>
                Avishek Das, AKM Shahariar Azad Rabby, <strong> Tahsin Zaman Jilan</strong>, Fuad Rahman </p>
              <p>
                International Conference on Pattern Recognition (ICPR 2022)
              </p>
              <!-- <p>
                  2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
                  Bangladesh
                </p> -->
              <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9956348" title="A Deep Learning Based Unified Solution for Character Recognition"><i
                  class="fa fa-file-pdf me-2"></i>Paper
              </a>
            </div>
              <div class="textarea">
                <h5 class="mb-1">Abstract</h5>
                <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;font-size: 15px;">
                  Optical Character Recognition(OCR) has become a crucial area of research due to the vast number of digitized documents to lessen the dependency on paper.
                  One can save time and money on data entry by automatically extracting information off paper and putting it where it needs to go.
                  There has been much research on OCR systems for different languages, but a unified system that is agnostic to language does not exist. 
                  In this work, we propose a multi-headed resunet++ based solution that can recognize the low resource languages(Bangla, Assamese, etc.) and performs well on resource-rich languages(such as English, Arabic, etc.). 
                  The backbone of the solution, i.e., resunet++, is fundamentally designed for medical image segmentation that is very complex. 
                  As the low representative languages are mostly of cursive style and complex in nature, this backbone can help share those higher-level features and pass them to the lower level.
                  Our proposed solution is applied to isolated characters of Bangla, Assamese, and English languages. 
                  For Bangla, the segmentation is done by our developed method, and the dataset was pre-segmented for the other two languages. 
                  Applying the solution, we achieved a satisfactory performance.
                </p>
              </div>
            <!-- <p>• Segmentation & Recognition of Bangla, Assamese and English (Handwritten, Typewritten, Computer Composed
              & Printed) characters</p> -->
          
          </div>





          <!-- <div class="flex-shrink-0">
            <span class="text-primary">[will be online soon]</span>
          </div> -->
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <!-- ADD NEW PAPER -->
          <div class="flex-grow-1">
            <h4 class="mb-0">
              Towards building a Bangla text recognition solution with a Multi-Headed CNN architecture
            </h4>
            <div class="subheading mb-3">
              <p> Md. Majedul Islam, Avishek Das, <strong>Tahsin Zaman Jilan</strong>, A K M Shahariar Azad Rabby, Nazmul Hasan, Fuad Rahman</p>
              <p>
                IEEE International Conference on Big Data (IEEE BigData2021)
              </p>
              <!-- <p>
              2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
              Bangladesh
            </p> -->
              <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9671653"
                title="Towards building a Bangla text recognition solution with a Multi-Headed CNN architecture"><i
                  class="fa fa-file-pdf me-2"></i>Paper
              </a>
            </div>
            <div class="textarea">
              <h5 class="mb-1">Abstract</h5>
              <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;">
                Bangla is among the ten most popular languages in the world by the number of speakers. 
                The task of Bangla recognition is quite challenging than other languages because of the existence of graphemes of multiple single characters, 
                and diacritics of vowels and consonants. The purpose of this study is to develop an innovative large-scale Bangla OCR solution based on character-level recognition. 
                Two types of documents were used to test our method: handwritten and printed. In addition, 
                our method was applied to the handwritten documents as well as three subdomains of the printed domain: 
                computer-composed, letterpress, and typewritten documents using our proposed attentionbased multi-headed CNN architecture. 
                Extensive testing shows that our method provides state-of-the-art performance on both handwritten and printed texts.
              </p>
            </div>

            <!-- <p>• Recognition of Bangla OCR (Handwritten, Typewritten, Computer Composed & Printed) characters</p> -->
            <p>
              • State-of-the-art performance on both handwritten and printed texts
            </p>
            <p> DOI: 10.1109/BigData52589.2021.9671653
            </p>
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">
              A Novel Approach to Enhance Safety on Drowsy Driving in Self-Driving Car
            </h4>
            <div class="subheading mb-3">
              <p>
                Md. Motaharul Islam; <strong>Tahsin Zaman Jilan</strong> ; Mashfiq
                Shahriar Zaman; Md. Fahmidur Rahman Sakib; Nazmus Saquib. (Springer Nature)
              </p>
              <!-- <p>
                      2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
                      Bangladesh
                    </p> -->
              <a target="_blank" href="https://link.springer.com/article/10.1007/s11036-022-01932-8"
                title="A Novel Approach to Enhance Safety on Drowsy Driving in Self-Driving Car"><i
                  class="fa fa-file-pdf me-2"></i>Paper
              </a>
            </div>
            <div class="textarea">
              <h5 class="mb-1">Abstract</h5>
              <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;">
                Drowsy driving centric accidents are increasing at a frightening rate. 
                Needless to say that the state-of-the-art technologies only have competencies in detecting drowsiness and alerting the drowsy driver. 
                Existing methods have some remarkable hindrances in the domain of handling the distressed situation.
                Therefore these methodologies are ineffective to take additional safety measures if the driver is not proficient enough to operate the vehicle even though an alarm is given.
                Consequently, after evaluating the existing methodologies and the growth of autonomous vehicles, 
                we have proposed an innovative approach that detects driver drowsiness in real-time. 
                Our suggested model can locate a nearest available safe parking space and reach the parking location after initiating the autonomous driving mode to ensure safety. 
                The proposed methodology has achieved an accuracy of 98%.
              </p>
            </div>
            <!-- <p>• Collected data on drowsy driving and analysed to detect drowsiness and
              proposed an algorithm to turn on autonomous mode to reach to a safe parking space</p> -->
            <p>
              • State-of-the-art approach to handle post-alarm condition on
              autonomous vehicle
            </p>
          </div>
          <div class="flex-shrink-0">
            <!-- <span class="text-primary">Python, Opencv, ML</span> -->
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">
              An Algorithmic Approach to Driver Drowsiness Detection for
              Ensuring Safety in an Autonomous Car
            </h4>
            <div class="subheading mb-3">
              <p>
                Md. Motaharul Islam; <strong>Tahsin Zaman Jilan</strong> ; Mashfiq
                Shahriar Zaman; Md. Fahmidur Rahman Sakib; Nazmus Saquib
              </p>
              <!-- <p>
                  2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
                  Bangladesh
                </p> -->
              <a target="_blank" href="https://ieeexplore.ieee.org/document/9230766"
                title="An Algorithmic Approach to Driver Drowsiness Detection for Ensuring Safety in an Autonomous Car"><i
                  class="fa fa-file-pdf me-2"></i>Paper
              </a>
            </div>
            <div class="textarea">
              <h5 class="mb-1">Abstract</h5>
              <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;">
                Human-centric accidents are increasing gradually and one of the dominant causes of the accidents is driver drowsiness. 
                Therefore, to lessen the accidents related to drowsiness, methods that are capable of observing facial expression to detect drowsiness have been proposed by researchers in recent decades to ensure safety. 
                However, the state-of-the-art models only have the competency in determining the drowsiness and alarming the driver. 
                Traditional approaches divide the detection method into two stages, such as detecting drowsiness from the driver's facial features and further apprising the driver.
                Hence, the existing models are inadequate to take any additional safety procedures to ensure more safety if the driver remains unable to operate the vehicle after giving an alarm.
                Analyzing these approaches and because of the increasing reliance on the vehicles, we have introduced an algorithmic approach in which the proposed system can locate a safe parking
                 space after the determination of drowsiness and can also deliver a distress message to the authority informing about the situation while reaching at the safe parking space to assure safety from the incompetent, drowsy driver.
              </p>
            </div>
            <!-- <p>• Real-Time driver observation using OpenCV & python API</p> -->
            <!-- <p>
              • State-of-the-art approach to handle post-alarm condition on
              autonomous vehicle
            </p>
            <p>
              • The system can book a local parking space and reach there if
              the driver is sleepy
            </p> -->
          </div>
          <div class="flex-shrink-0">
            <!-- <span class="text-primary">Python, Opencv, ML</span> -->
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h4 class="mb-0">
              An efficient Metaheuristic Approach for Finding Motifs from DNA Sequences
            </h4>
            <div class="subheading mb-3">
              <p>
                Syed Md. Shamsul Alam, <strong>Tahsin Zaman Jilan</strong>, Md. Al-Junaed Islam, Shurid Shahriar Zaman, Faisal Bin Ashraf
              </p>
              <!-- <p>
                  2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka,
                  Bangladesh
                </p> -->
              <a target="_blank" href="https://ieeexplore.ieee.org/document/9733453"
                title="A Deep Learning Based Unified Solution for Character Recognition"><i
                  class="fa fa-file-pdf me-2"></i>Paper
              </a>
            </div>
            <div class="textarea">
              <h5 class="mb-1">Abstract</h5>
              <p style="text-align:justify; background-color:rgb(232, 236, 239);color:black;">
                Finding patterns of the short sequences in DNA, RNA protein sequence has immense biological significance. 
                The characterization and recognition of motifs is therefore an important method for a more in-depth understanding of genes or proteins in their structure, 
                function and relations of evolution. This is one of the classical problems in the field of computational biology and which is an NP Hard problem. 
                In this paper, we have proposed an evolutionary approach to get the motifs from DNA sequence by searching candidate motifs using heuristic way from the data. 
                We have included various mutation techniques in an evolutionary approach and found an efficient way to calculate the fitness of our candidate motifs. 
                We have evaluated the fitness of found motifs from our approach with benchmark data sets.
                Our method performs better results in terms of accuracy and specificity.
              </p>
            </div>
            <!-- <p>• Created an algorithm that can find DNA motif using heuristic approach</p> -->
            <p>
              <!-- • Learned various core heuristic approach and analysed how they affect the population -->
            </p>

          </div>
        </div>
      </div>
    </section>
    <hr class="m-0" />


    <!-- Skills-->
    <section class="resume-section" id="skills">
      <div class="resume-section-content">
        <h2 class="mb-5">Skills</h2>

        <div class="subheading mb-3">Programming Languages & Tools</div>
        <ul class="list-inline dev-icons">
          <li class="list-inline-item"><i class="fab fa-python"></i></li>
          <li class="list-inline-item"><i class="fab fa-java"></i></li>
          <li class="list-inline-item"><i class="fab fa-js-square"></i></li>
          <li class="list-inline-item"><i class="fab fa-cuttlefish"></i></li>
          <li class="list-inline-item"><i class="fab fa-react"></i></li>
        </ul>
        
        <ul class="list-inline dev-icons">
          <li class="list-inline-item"><i class="fab fa-git-alt"></i></li>
          <li class="list-inline-item"><i class="fab fa-vuejs"></i></li>
          <li class="list-inline-item"><i class="fab fa-node-js"></i></li>
          <li class="list-inline-item"><i class="fas fa-database"></i></li>
        </ul>

        <div class="subheading mb-3">Workflow</div>
        <ul class="fa-ul mb-0">
          <!-- <li>
            <span class="fa-li"><i class="fas fa-check"></i></span>
            <strong>Speaking Languages:</strong> Bangla, English, Hindi,
            German(basic).
          </li> -->
          <li>
            <span class="fa-li"><i class="fas fa-check"></i></span>
            <strong>Programming Languages:</strong> Python, C/C++(Basic), JavaScript, SQL.
          </li>
          <li>
            <span class="fa-li"><i class="fas fa-check"></i></span>
            <strong>Machine Learning Frameworks:</strong> Pytorch Scikit Learn, Numpy, Pandas.
          </li>
          <li>
            <span class="fa-li"><i class="fas fa-check"></i></span>
            <strong>Web Development Frameworks:</strong> HTML, CSS, Tailwind CSS, JavaScript, React, Node.js, Express.
          </li>
          <li>
            <span class="fa-li"><i class="fas fa-check"></i></span>
            <strong>Others:</strong> Git, Latex. 
          </li>

        </ul>
      </div>
    </section>
    <hr class="m-0" />


    <!-- Awards-->
    <section class="resume-section" id="awards">
      <div class="resume-section-content">
        <h2 class="mb-5">Achievements</h2>
        <ul class="fa-ul mb-0">
          <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            Competitive Programming
            <p>• Solved 400+ problems on Codeforces, Leetcode ranging in various difficulties.</p>
          </li>
          <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            BRACU Intra Programming Contest 2021
            <p>• Attained the 3rd position among 300 students in BRAC University.</p>
          </li>
          <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            Meta Hacker Cup 2024
            <p>Top 35% in World Wide Competition</p>
          </li>
        </ul>
      </div>
    </section>
    <hr class="m-0" />

    <!-- Projects -->
    <section class="resume-section" id="projects">
      <div class="resume-section-content">
        <h2 class="mb-5">Projects & Hackathons</h2>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h3 class="mb-0">ROBI DATATHON 2.0</h3>
            <div class="subheading mb-3">
              <a target="_blank" href="https://github.com/Tahsin-Zaman-Jilan/Robi-Datathon-2.0" title="ROBI DATATHON 2.0">
                <i class="fab fa-github me-2 ms-3"></i>Code
              </a>
            </div>
            <p>• Reached final round of the Hackathon(top 5%)</p>
            <p>• Successfully developed multiple solutions to predict outcomes effectively using Machine Learning techniques</p>
            <p>• Employed the MinMaxScaler pre-processing technique to enhance the performance and accuracy of label column data</p>
            <p>• Successfully attained an impressive accuracy rate of 86% through the implementation of a Neural Network model using the Keras API</p>
          </div>
          <div class="flex-shrink-0">
            <span class="text-primary">Machine Learning, Neural Networks, Keras</span>
          </div>
        </div>

        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h3 class="mb-0">Hate Speech Detection</h3>
            <div class="subheading mb-3">
              <a target="_blank" href="https://github.com/Tahsin-Zaman-Jilan/Sentiment-Analysis-" title="Hate Speech Detection">
                <i class="fab fa-github me-2 ms-3"></i>Code
              </a>
            </div>
            <p>• Detected Hate Speech with the development of BiLSTM, LSTM, GRU, ConV1D, and BERT using Tensorflow and Keras API</p>
            <p>• Implemented Tokenization and random undersampling as pre-processing techniques, enhancing data handling and class imbalance</p>
            <p>• Accomplished an exceptional accuracy rate of 99% by leveraging a BiLSTM (Bidirectional Long Short-Term Memory) model</p>
          </div>
          <div class="flex-shrink-0">
            <span class="text-primary">Deep Learning, NLP, TensorFlow</span>
          </div>
        </div>
        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="flex-grow-1">
            <h3 class="mb-0">Bangla ChatBot</h3>
            <div class="subheading mb-3">
              <a target="_blank" href="https://github.com/Tahsin-Zaman-Jilan/BanglaChatBot-A-deep-Learning-Approach" title="BanglaChatBot-A-deep-Learning-Approach">
                <i class="fab fa-github me-2 ms-3"></i>Code
              </a>
            </div>
            <p>• BanglaBot is a Bangla chatbot powered by a Neural Network model designed to comprehend and respond to user queries in Bengali. The project utilized two datasets for training, covering diverse conversational contexts. Various models, including BanglaBERT, DistilBERT, and Sequential models, were employed to enhance language understanding and performance.</p>
            <p>• BanglaBot aims to provide a user-friendly chatbot experience for Bengali speakers, enabling them to communicate and receive information comfortably in their native language.</p>
            <p>• Models used include DistilBERT for tokenization, BanglaBERT for enhanced NLP, a Sequential model for intent-based responses, and a hybrid model combining both for dynamic interaction.</p>
          </div>
          <div class="flex-shrink-0">
            <span class="text-primary">Deep Learning, NLP, TensorFlow, BanglaBERT, DistilBERT</span>
          </div>
        </div>
      </div>
    </section>
    
    <!-- Interests-->
<!--     <section class="resume-section" id="interests">
      <div class="resume-section-content">
        <h2 class="mb-5">Interests</h2>
        <div class="interests-images">
          <div class="image-frame">
            <img src="assets/img/tokyo_ghoul.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/itachi.webp" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/naruto.png" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/hisoka.avif" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/bleach.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/makima.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/hero.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/itaduri.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/demon-slayer.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/fma.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/AOT.png" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/code.jpg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/anya.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/vinland.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/asta.jpeg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">
            <img src="assets/img/hellsing.jpg" alt="Anime 1" class="img-fluid img-profile rounded-circle mx-auto mb-1"style="width: 100px; height: 100px;">

          </div>
          <!-- Add more images or text-based interests as needed -->
<!--         </div>
        <p>I enjoy traveling, savoring coffee, watching TV series and anime, and during my leisure time, I'm an avid FPS gamer [ign: ISamuraiI #7775].
        </p>
      </div>
    </section>     -->
    <hr class="m-0" />
  </div>

  <!-- Bootstrap core JS-->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>

  <!-- Core theme JS-->
  <script src="js/scripts.js"></script>
</body>

</html>

